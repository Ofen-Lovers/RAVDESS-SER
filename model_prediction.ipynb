{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "fs = 16000  # RAVDESS sample rate\n",
    "duration = 3  # seconds\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "sd.wait()\n",
    "sf.write(\"my_voice.wav\", audio, fs)\n",
    "print(\"Saved as my_voice.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85209a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping numeric emotion IDs to readable labels\n",
    "emotion_mapping = {\n",
    "    1: \"neutral\",\n",
    "    2: \"calm\",\n",
    "    3: \"happy\",\n",
    "    4: \"sad\",\n",
    "    5: \"angry\",\n",
    "    6: \"fearful\",\n",
    "    7: \"disgust\",\n",
    "    8: \"surprised\"\n",
    "}\n",
    "\n",
    "def predict_emotion(audio_path, model, scaler):\n",
    "    features = extract_features(audio_path).reshape(1, -1)\n",
    "    features_scaled = scaler.transform(features)\n",
    "    pred_id = model.predict(features_scaled)[0]\n",
    "    return emotion_mapping.get(pred_id, \"Unknown\")\n",
    "\n",
    "# -------------------------\n",
    "audio_path = \"my_voice.wav\"\n",
    "\n",
    "predicted_logreg = predict_emotion(audio_path, logreg, scaler)\n",
    "print(\"Predicted emotion (Logistic Regression):\", predicted_logreg)\n",
    "\n",
    "predicted_svm = predict_emotion(audio_path, svm_rbf, scaler)\n",
    "print(\"Predicted emotion (RBF SVM):\", predicted_svm)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
